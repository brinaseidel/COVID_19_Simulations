{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create feather file format to investigate if it speeds up data loading\n",
    "import feather\n",
    "path = 'data/nyc_od.csv'\n",
    "OD = pd.read_csv(path, header=None, dtype=np.float64)\n",
    "path = 'data/nyc_od.feather'\n",
    "feather.write_dataframe(OD, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from multiprocessing import cpu_count\n",
    "from functools import partial\n",
    "from multiprocessing.pool import Pool\n",
    "import pandas as pd\n",
    "\n",
    "# Matplotlib doesn't play nicely with multiprocessing, so\n",
    "# we have to create a separate graphing function & import matplotlib inside of that.\n",
    "def graphing_function(args, days, norms):\n",
    "    import matplotlib.pyplot as plt\n",
    "    susceptible_pop_norm, infected_pop_norm, recovered_pop_norm = norms\n",
    "    # plot results and save the plot\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.plot(np.arange(days), susceptible_pop_norm, label='Susceptible', color='#4aa5f0', linewidth=2)\n",
    "    ax.plot(np.arange(days), infected_pop_norm, label='Infected', color='#f03737', linewidth=2)\n",
    "    ax.plot(np.arange(days), recovered_pop_norm, label='Recovered', color='#82e88a', linewidth=2)\n",
    "    ax.legend(frameon=False)\n",
    "    ax.set_xlabel(\"Days\")\n",
    "    ax.set_ylabel(\"Share of Population\")\n",
    "    if 'fig_name' in args:\n",
    "        ax.figure.savefig('figures/' + args.fig_name + '.png')\n",
    "    else:\n",
    "        ax.figure.savefig('figures/sir_plot.png')\n",
    "    plt.close()\n",
    "    \n",
    "# Convenience function: access Python dict keys as dict.key instead of dict['key']\n",
    "class objdict(dict):\n",
    "    def __getattr__(self, name):\n",
    "        if name in self:\n",
    "            return self[name]\n",
    "        else:\n",
    "            raise AttributeError(\"No such attribute: \" + name)\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value\n",
    "\n",
    "    def __delattr__(self, name):\n",
    "        if name in self:\n",
    "            del self[name]\n",
    "        else:\n",
    "            raise AttributeError(\"No such attribute: \" + name)\n",
    "            \n",
    "# Run n simulations in parallel: for each run, parameters are randomly sampled from an interval\n",
    "# NOTE: Are these intervals reasonable?\n",
    "def multiprocess(args):\n",
    "\n",
    "    chunks = []\n",
    "    num_procs = args.randomize\n",
    "    for _ in range(num_procs):\n",
    "        d = dict()\n",
    "        d['origin_matrix_path'] = args.origin_matrix_path\n",
    "        d['thresh1'] = np.random.randint(0, 350)\n",
    "        d['thresh2'] = np.random.randint(d['thresh1'], 700)\n",
    "        d['infection_magnitude'] = np.random.randint(5, 15)\n",
    "        d['beta'] = 1.6\n",
    "        d['gamma'] = 0.04\n",
    "        d['public_trans'] = np.random.randint(1, 7) * 0.1\n",
    "        d['days'] = 200\n",
    "        d['fig_name'] = 'public_trans_{:0.1f}_({}, {})_inf_{}'.format(d['public_trans'], d['thresh1'], d['thresh2'], d['infection_magnitude'])\n",
    "        d['loading'] = args.loading\n",
    "        d = objdict(d)\n",
    "        chunks.append(d)\n",
    "\n",
    "    with Pool(num_procs) as p:\n",
    "        p.map(covid_sim, chunks)\n",
    "\n",
    "    p.join()\n",
    "\n",
    "def covid_sim(args):\n",
    "    # Read in origin-destination flow matrix\n",
    "    if int(args.loading) == 0:\n",
    "        OD = np.genfromtxt(args.origin_matrix_path, delimiter=',')\n",
    "        \n",
    "    elif int(args.loading) == 1:\n",
    "        OD = pd.read_csv('data/nyc_od.csv', header=None, dtype=np.float64).to_numpy()\n",
    "        \n",
    "    elif int(args.loading) == 2:\n",
    "        OD = feather.read_dataframe('data/nyc_od.feather').to_numpy()\n",
    "    \n",
    "\n",
    "    # initialize the population vector from the origin-destination flow matrix\n",
    "    N_k = np.abs(np.diagonal(OD) + OD.sum(axis=0) - OD.sum(axis=1))\n",
    "    locs_len = len(N_k)                 # number of locations\n",
    "    SIR = np.zeros(shape=(locs_len, 3)) # make a numpy array with 3 columns for keeping track of the S, I, R groups\n",
    "    SIR[:,0] = N_k                      # initialize the S group with the respective populations\n",
    "    thresh1 = args.thresh1\n",
    "    thresh2 = args.thresh2\n",
    "\n",
    "    first_infections = np.where((thresh1 <= SIR[:, 0]) & (SIR[:, 0] <= thresh2), np.random.randint(1, args.infection_magnitude), 0)   # for demo purposes, randomly introduce infections\n",
    "    # NOTE: this is arbitrary but not actually random.... \n",
    "    SIR[:, 0] = SIR[:, 0] - first_infections\n",
    "    SIR[:, 1] = SIR[:, 1] + first_infections                           # move infections to the I group\n",
    "\n",
    "    # row normalize the SIR matrix for keeping track of group proportions\n",
    "    row_sums = SIR.sum(axis=1)\n",
    "    SIR_n = SIR / row_sums[:, np.newaxis]\n",
    "\n",
    "    # initialize parameters\n",
    "    beta = args.beta\n",
    "    gamma = args.gamma\n",
    "    public_trans = args.public_trans                                 # alpha\n",
    "    R0 = beta/gamma\n",
    "    beta_vec = np.random.gamma(1.6, 2, locs_len)\n",
    "    gamma_vec = np.full(locs_len, gamma)\n",
    "    public_trans_vec = np.full(locs_len, public_trans)\n",
    "\n",
    "    # make copy of the SIR matrices \n",
    "    SIR_sim = SIR.copy()\n",
    "    SIR_nsim = SIR_n.copy()\n",
    "\n",
    "    # run model\n",
    "    #print(SIR_sim.sum(axis=0).sum() == N_k.sum())\n",
    "    infected_pop_norm = []\n",
    "    susceptible_pop_norm = []\n",
    "    recovered_pop_norm = []\n",
    "    days = 100\n",
    "    for time_step in tqdm(range(days)):\n",
    "        infected_mat = np.array([SIR_nsim[:,1],]*locs_len).transpose()\n",
    "        OD_infected = np.round(OD*infected_mat)\n",
    "        inflow_infected = OD_infected.sum(axis=0)\n",
    "        inflow_infected = np.round(inflow_infected*public_trans_vec)\n",
    "        #print('total infected inflow: ', inflow_infected.sum())\n",
    "        new_infect = beta_vec*SIR_sim[:, 0]*inflow_infected/(N_k + OD.sum(axis=0))\n",
    "        new_recovered = gamma_vec*SIR_sim[:, 1]\n",
    "        new_infect = np.where(new_infect>SIR_sim[:, 0], SIR_sim[:, 0], new_infect)\n",
    "        SIR_sim[:, 0] = SIR_sim[:, 0] - new_infect\n",
    "        SIR_sim[:, 1] = SIR_sim[:, 1] + new_infect - new_recovered\n",
    "        SIR_sim[:, 2] = SIR_sim[:, 2] + new_recovered\n",
    "        SIR_sim = np.where(SIR_sim<0,0,SIR_sim)\n",
    "        # recompute the normalized SIR matrix\n",
    "        row_sums = SIR_sim.sum(axis=1)\n",
    "        SIR_nsim = SIR_sim / row_sums[:, np.newaxis]\n",
    "        S = SIR_sim[:,0].sum()/N_k.sum()\n",
    "        I = SIR_sim[:,1].sum()/N_k.sum()\n",
    "        R = SIR_sim[:,2].sum()/N_k.sum()\n",
    "        #print(S, I, R, (S+I+R)*N_k.sum(), N_k.sum())\n",
    "        #print('\\n')\n",
    "        infected_pop_norm.append(I)\n",
    "        susceptible_pop_norm.append(S)\n",
    "        recovered_pop_norm.append(R)\n",
    "\n",
    "    graphing_function(args, days, (susceptible_pop_norm, infected_pop_norm, recovered_pop_norm))\n",
    "\n",
    "def covid_sim_serial(args):\n",
    "    for i in range(args.randomize):\n",
    "        covid_sim(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--loading'], dest='loading', nargs=None, const=None, default=0, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='COVID Simulator')\n",
    "parser.add_argument('--randomize', type=int, default=0)\n",
    "parser.add_argument('--origin-matrix-path', default='data/nyc_od.csv')\n",
    "parser.add_argument('--thresh1', type=int, default=0)\n",
    "parser.add_argument('--thresh2', type=int, default=200)\n",
    "parser.add_argument('--infection-magnitude', type=int, default=10)\n",
    "parser.add_argument('--beta', type=float, default=1.6)\n",
    "parser.add_argument('--gamma', type=float, default=0.04)\n",
    "parser.add_argument('--public-trans', type=float, default=0.5)\n",
    "parser.add_argument('--days', type=int, default=100)\n",
    "parser.add_argument('--img-folder', default='figures/')\n",
    "parser.add_argument('--loading', default = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "args1 = parser.parse_args(\"--randomize 4 --gamma 0.05 --loading 0\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line Profiler Analysis\n",
    "\n",
    "Using lprun, we see that most of the time is spent loading in the Origin-Destination flow matrix (accounts for 39.2% of the time) and computing the element-wise matrix multiplication OD\\*infected_mat and rounding it (accounts for 43.8% of the time). Note that the matrix multiplication occurs in a for-loop that runs multiple times while the loading of the matrix occurs only once. The percentage of time needed to perform all of the matrix multiplications at all of the time steps is roughly the same as the time needed to load in the matrix. We will first focus on trying read the OD matrix faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 22.45it/s]\n"
     ]
    }
   ],
   "source": [
    "%lprun -f covid_sim covid_sim(args1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 8.6986 s\n",
    "File: <ipython-input-207-f0250d20bd69>\n",
    "Function: covid_sim at line 75\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    75                                           def covid_sim(args):\n",
    "    76                                               # Read in origin-destination flow matrix\n",
    "    77         1          5.0      5.0      0.0      if int(args.loading) == 0:\n",
    "    78         1    4130138.0 4130138.0     47.5          OD = np.genfromtxt(args.origin_matrix_path, delimiter=',')\n",
    "    79                                                   \n",
    "    80                                               elif int(args.loading) == 1:\n",
    "    81                                                   OD = pd.read_csv('data/nyc_od.csv', header=None, dtype=np.float64).to_numpy()\n",
    "    82                                                   \n",
    "    83                                               elif int(args.loading) == 2:\n",
    "    84                                                   OD = feather.read_dataframe('data/nyc_od.feather').to_numpy()\n",
    "    85                                               \n",
    "    86                                           \n",
    "    87                                               # initialize the population vector from the origin-destination flow matrix\n",
    "    88         1       6776.0   6776.0      0.1      N_k = np.abs(np.diagonal(OD) + OD.sum(axis=0) - OD.sum(axis=1))\n",
    "    89         1          3.0      3.0      0.0      locs_len = len(N_k)                 # number of locations\n",
    "    90         1         32.0     32.0      0.0      SIR = np.zeros(shape=(locs_len, 3)) # make a numpy array with 3 columns for keeping track of the S, I, R groups\n",
    "    91         1          7.0      7.0      0.0      SIR[:,0] = N_k                      # initialize the S group with the respective populations\n",
    "    92         1         14.0     14.0      0.0      thresh1 = args.thresh1\n",
    "    93         1          1.0      1.0      0.0      thresh2 = args.thresh2\n",
    "    94                                           \n",
    "    95         1         75.0     75.0      0.0      first_infections = np.where((thresh1 <= SIR[:, 0]) & (SIR[:, 0] <= thresh2), np.random.randint(1, args.infection_magnitude), 0)   # for demo purposes, randomly introduce infections\n",
    "    96                                               # NOTE: this is arbitrary but not actually random.... \n",
    "    97         1         13.0     13.0      0.0      SIR[:, 0] = SIR[:, 0] - first_infections\n",
    "    98         1          9.0      9.0      0.0      SIR[:, 1] = SIR[:, 1] + first_infections                           # move infections to the I group\n",
    "    99                                           \n",
    "   100                                               # row normalize the SIR matrix for keeping track of group proportions\n",
    "   101         1         47.0     47.0      0.0      row_sums = SIR.sum(axis=1)\n",
    "   102         1         77.0     77.0      0.0      SIR_n = SIR / row_sums[:, np.newaxis]\n",
    "   103                                           \n",
    "   104                                               # initialize parameters\n",
    "   105         1          2.0      2.0      0.0      beta = args.beta\n",
    "   106         1          1.0      1.0      0.0      gamma = args.gamma\n",
    "   107         1          1.0      1.0      0.0      public_trans = args.public_trans                                 # alpha\n",
    "   108         1          1.0      1.0      0.0      R0 = beta/gamma\n",
    "   109         1        144.0    144.0      0.0      beta_vec = np.random.gamma(1.6, 2, locs_len)\n",
    "   110         1         41.0     41.0      0.0      gamma_vec = np.full(locs_len, gamma)\n",
    "   111         1         13.0     13.0      0.0      public_trans_vec = np.full(locs_len, public_trans)\n",
    "   112                                           \n",
    "   113                                               # make copy of the SIR matrices \n",
    "   114         1          4.0      4.0      0.0      SIR_sim = SIR.copy()\n",
    "   115         1         28.0     28.0      0.0      SIR_nsim = SIR_n.copy()\n",
    "   116                                           \n",
    "   117                                               # run model\n",
    "   118                                               #print(SIR_sim.sum(axis=0).sum() == N_k.sum())\n",
    "   119         1          2.0      2.0      0.0      infected_pop_norm = []\n",
    "   120         1          1.0      1.0      0.0      susceptible_pop_norm = []\n",
    "   121         1          1.0      1.0      0.0      recovered_pop_norm = []\n",
    "   122         1          1.0      1.0      0.0      days = 100\n",
    "   123       101      27182.0    269.1      0.3      for time_step in tqdm(range(days)):\n",
    "   124       100     686178.0   6861.8      7.9          infected_mat = np.array([SIR_nsim[:,1],]*locs_len).transpose()\n",
    "   125       100    3147535.0  31475.3     36.2          OD_infected = np.round(OD*infected_mat)\n",
    "   126       100     276859.0   2768.6      3.2          inflow_infected = OD_infected.sum(axis=0)\n",
    "   127       100       3205.0     32.0      0.0          inflow_infected = np.round(inflow_infected*public_trans_vec)\n",
    "   128                                                   #print('total infected inflow: ', inflow_infected.sum())\n",
    "   129       100     296623.0   2966.2      3.4          new_infect = beta_vec*SIR_sim[:, 0]*inflow_infected/(N_k + OD.sum(axis=0))\n",
    "   130       100       1077.0     10.8      0.0          new_recovered = gamma_vec*SIR_sim[:, 1]\n",
    "   131       100       1404.0     14.0      0.0          new_infect = np.where(new_infect>SIR_sim[:, 0], SIR_sim[:, 0], new_infect)\n",
    "   132       100        947.0      9.5      0.0          SIR_sim[:, 0] = SIR_sim[:, 0] - new_infect\n",
    "   133       100        915.0      9.2      0.0          SIR_sim[:, 1] = SIR_sim[:, 1] + new_infect - new_recovered\n",
    "   134       100        603.0      6.0      0.0          SIR_sim[:, 2] = SIR_sim[:, 2] + new_recovered\n",
    "   135       100       2367.0     23.7      0.0          SIR_sim = np.where(SIR_sim<0,0,SIR_sim)\n",
    "   136                                                   # recompute the normalized SIR matrix\n",
    "   137       100       4347.0     43.5      0.0          row_sums = SIR_sim.sum(axis=1)\n",
    "   138       100       2401.0     24.0      0.0          SIR_nsim = SIR_sim / row_sums[:, np.newaxis]\n",
    "   139       100       1510.0     15.1      0.0          S = SIR_sim[:,0].sum()/N_k.sum()\n",
    "   140       100        845.0      8.4      0.0          I = SIR_sim[:,1].sum()/N_k.sum()\n",
    "   141       100        816.0      8.2      0.0          R = SIR_sim[:,2].sum()/N_k.sum()\n",
    "   142                                                   #print(S, I, R, (S+I+R)*N_k.sum(), N_k.sum())\n",
    "   143                                                   #print('\\n')\n",
    "   144       100        187.0      1.9      0.0          infected_pop_norm.append(I)\n",
    "   145       100         97.0      1.0      0.0          susceptible_pop_norm.append(S)\n",
    "   146       100        147.0      1.5      0.0          recovered_pop_norm.append(R)\n",
    "   147                                           \n",
    "   148         1     105914.0 105914.0      1.2      graphing_function(args, days, (susceptible_pop_norm, infected_pop_norm, recovered_pop_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try data loading using pandas, given by loading argument value of 1 and feather, given by loading argument value of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "args2 = parser.parse_args(\"--randomize 4 --gamma 0.05 --loading 1\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "args3 = parser.parse_args(\"--randomize 4 --gamma 0.05 --loading 2\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 17.71it/s]\n",
      "100%|██████████| 100/100 [00:04<00:00, 20.77it/s]\n",
      "100%|██████████| 100/100 [00:04<00:00, 20.18it/s]\n",
      "100%|██████████| 100/100 [00:04<00:00, 20.13it/s]\n"
     ]
    }
   ],
   "source": [
    "%lprun -f covid_sim_serial covid_sim_serial(args1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 21.9654 s\n",
    "File: <ipython-input-188-f0250d20bd69>\n",
    "Function: covid_sim_serial at line 150\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "   150                                           def covid_sim_serial(args):\n",
    "   151         5         19.0      3.8      0.0      for i in range(args.randomize):\n",
    "   152         4   21965370.0 5491342.5    100.0          covid_sim(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 28.56it/s]\n",
      "100%|██████████| 100/100 [00:03<00:00, 21.54it/s]\n",
      "100%|██████████| 100/100 [00:03<00:00, 29.49it/s]\n",
      "100%|██████████| 100/100 [00:03<00:00, 26.25it/s]\n"
     ]
    }
   ],
   "source": [
    "%lprun -f covid_sim_serial covid_sim_serial(args2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 18.9244 s\n",
    "File: <ipython-input-207-f0250d20bd69>\n",
    "Function: covid_sim_serial at line 150\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "   150                                           def covid_sim_serial(args):\n",
    "   151         5         16.0      3.2      0.0      for i in range(args.randomize):\n",
    "   152         4   18924377.0 4731094.2    100.0          covid_sim(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 26.57it/s]\n",
      "100%|██████████| 100/100 [00:03<00:00, 30.79it/s]\n",
      "100%|██████████| 100/100 [00:03<00:00, 30.87it/s]\n",
      "100%|██████████| 100/100 [00:03<00:00, 30.35it/s]\n"
     ]
    }
   ],
   "source": [
    "%lprun -f covid_sim_serial covid_sim_serial(args3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 14.6464 s\n",
    "File: <ipython-input-207-f0250d20bd69>\n",
    "Function: covid_sim_serial at line 150\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "   150                                           def covid_sim_serial(args):\n",
    "   151         5        232.0     46.4      0.0      for i in range(args.randomize):\n",
    "   152         4   14646201.0 3661550.2    100.0          covid_sim(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.06it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  7.38it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.42it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.40it/s]\n"
     ]
    }
   ],
   "source": [
    "%lprun -f multiprocess multiprocess(args1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 21.4746 s\n",
    "File: <ipython-input-207-f0250d20bd69>\n",
    "Function: multiprocess at line 51\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    51                                           def multiprocess(args):\n",
    "    52                                           \n",
    "    53         1          1.0      1.0      0.0      chunks = []\n",
    "    54         1         29.0     29.0      0.0      num_procs = args.randomize\n",
    "    55         5          5.0      1.0      0.0      for _ in range(num_procs):\n",
    "    56         4          4.0      1.0      0.0          d = dict()\n",
    "    57         4          7.0      1.8      0.0          d['origin_matrix_path'] = args.origin_matrix_path\n",
    "    58         4         87.0     21.8      0.0          d['thresh1'] = np.random.randint(0, 350)\n",
    "    59         4         12.0      3.0      0.0          d['thresh2'] = np.random.randint(d['thresh1'], 700)\n",
    "    60         4          8.0      2.0      0.0          d['infection_magnitude'] = np.random.randint(5, 15)\n",
    "    61         4          4.0      1.0      0.0          d['beta'] = 1.6\n",
    "    62         4          1.0      0.2      0.0          d['gamma'] = 0.04\n",
    "    63         4         10.0      2.5      0.0          d['public_trans'] = np.random.randint(1, 7) * 0.1\n",
    "    64         4          1.0      0.2      0.0          d['days'] = 200\n",
    "    65         4         12.0      3.0      0.0          d['fig_name'] = 'public_trans_{:0.1f}_({}, {})_inf_{}'.format(d['public_trans'], d['thresh1'], d['thresh2'], d['infection_magnitude'])\n",
    "    66         4          2.0      0.5      0.0          d['loading'] = args.loading\n",
    "    67         4         17.0      4.2      0.0          d = objdict(d)\n",
    "    68         4          3.0      0.8      0.0          chunks.append(d)\n",
    "    69                                           \n",
    "    70         1      35045.0  35045.0      0.2      with Pool(num_procs) as p:\n",
    "    71         1   21439360.0 21439360.0     99.8          p.map(covid_sim, chunks)\n",
    "    72                                           \n",
    "    73         1         34.0     34.0      0.0      p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.11it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.89it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00, 11.35it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.71it/s]\n"
     ]
    }
   ],
   "source": [
    "%lprun -f multiprocess multiprocess(args2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 12.5935 s\n",
    "File: <ipython-input-207-f0250d20bd69>\n",
    "Function: multiprocess at line 51\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    51                                           def multiprocess(args):\n",
    "    52                                           \n",
    "    53         1          1.0      1.0      0.0      chunks = []\n",
    "    54         1         12.0     12.0      0.0      num_procs = args.randomize\n",
    "    55         5          5.0      1.0      0.0      for _ in range(num_procs):\n",
    "    56         4          4.0      1.0      0.0          d = dict()\n",
    "    57         4          4.0      1.0      0.0          d['origin_matrix_path'] = args.origin_matrix_path\n",
    "    58         4         63.0     15.8      0.0          d['thresh1'] = np.random.randint(0, 350)\n",
    "    59         4         11.0      2.8      0.0          d['thresh2'] = np.random.randint(d['thresh1'], 700)\n",
    "    60         4          9.0      2.2      0.0          d['infection_magnitude'] = np.random.randint(5, 15)\n",
    "    61         4          2.0      0.5      0.0          d['beta'] = 1.6\n",
    "    62         4          3.0      0.8      0.0          d['gamma'] = 0.04\n",
    "    63         4          9.0      2.2      0.0          d['public_trans'] = np.random.randint(1, 7) * 0.1\n",
    "    64         4          0.0      0.0      0.0          d['days'] = 200\n",
    "    65         4         11.0      2.8      0.0          d['fig_name'] = 'public_trans_{:0.1f}_({}, {})_inf_{}'.format(d['public_trans'], d['thresh1'], d['thresh2'], d['infection_magnitude'])\n",
    "    66         4          3.0      0.8      0.0          d['loading'] = args.loading\n",
    "    67         4          5.0      1.2      0.0          d = objdict(d)\n",
    "    68         4          2.0      0.5      0.0          chunks.append(d)\n",
    "    69                                           \n",
    "    70         1      37405.0  37405.0      0.3      with Pool(num_procs) as p:\n",
    "    71         1   12555861.0 12555861.0     99.7          p.map(covid_sim, chunks)\n",
    "    72                                           \n",
    "    73         1         64.0     64.0      0.0      p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00, 10.26it/s]\n",
      "\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.55it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00, 10.45it/s]\n"
     ]
    }
   ],
   "source": [
    "%lprun -f multiprocess multiprocess(args3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 11.3945 s\n",
    "File: <ipython-input-207-f0250d20bd69>\n",
    "Function: multiprocess at line 51\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    51                                           def multiprocess(args):\n",
    "    52                                           \n",
    "    53         1          2.0      2.0      0.0      chunks = []\n",
    "    54         1         19.0     19.0      0.0      num_procs = args.randomize\n",
    "    55         5          6.0      1.2      0.0      for _ in range(num_procs):\n",
    "    56         4          4.0      1.0      0.0          d = dict()\n",
    "    57         4          7.0      1.8      0.0          d['origin_matrix_path'] = args.origin_matrix_path\n",
    "    58         4         65.0     16.2      0.0          d['thresh1'] = np.random.randint(0, 350)\n",
    "    59         4         10.0      2.5      0.0          d['thresh2'] = np.random.randint(d['thresh1'], 700)\n",
    "    60         4         25.0      6.2      0.0          d['infection_magnitude'] = np.random.randint(5, 15)\n",
    "    61         4          3.0      0.8      0.0          d['beta'] = 1.6\n",
    "    62         4          2.0      0.5      0.0          d['gamma'] = 0.04\n",
    "    63         4         11.0      2.8      0.0          d['public_trans'] = np.random.randint(1, 7) * 0.1\n",
    "    64         4          3.0      0.8      0.0          d['days'] = 200\n",
    "    65         4         11.0      2.8      0.0          d['fig_name'] = 'public_trans_{:0.1f}_({}, {})_inf_{}'.format(d['public_trans'], d['thresh1'], d['thresh2'], d['infection_magnitude'])\n",
    "    66         4          2.0      0.5      0.0          d['loading'] = args.loading\n",
    "    67         4          5.0      1.2      0.0          d = objdict(d)\n",
    "    68         4          3.0      0.8      0.0          chunks.append(d)\n",
    "    69                                           \n",
    "    70         1      63073.0  63073.0      0.6      with Pool(num_procs) as p:\n",
    "    71         1   11331233.0 11331233.0     99.4          p.map(covid_sim, chunks)\n",
    "    72                                           \n",
    "    73         1         35.0     35.0      0.0      p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that loading data with feather works the fastest, so we'll be using that going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving Matrix Multiplication using Cython\n",
    "\n",
    "We want to investigate if using Cython can provide a greater speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "# cython: profile=True\n",
    "# cython: linetrace=True\n",
    "# cython: binding=True\n",
    "# distutils: define_macros=CYTHON_TRACE_NOGIL=1\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from multiprocessing import cpu_count\n",
    "from functools import partial\n",
    "from multiprocessing.pool import Pool\n",
    "import pandas as pd\n",
    "import feather\n",
    "\n",
    "# Matplotlib doesn't play nicely with multiprocessing, so\n",
    "# we have to create a separate graphing function & import matplotlib inside of that.\n",
    "def graphing_function(args, days, norms):\n",
    "    import matplotlib.pyplot as plt\n",
    "    susceptible_pop_norm, infected_pop_norm, recovered_pop_norm = norms\n",
    "    # plot results and save the plot\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.plot(np.arange(days), susceptible_pop_norm, label='Susceptible', color='#4aa5f0', linewidth=2)\n",
    "    ax.plot(np.arange(days), infected_pop_norm, label='Infected', color='#f03737', linewidth=2)\n",
    "    ax.plot(np.arange(days), recovered_pop_norm, label='Recovered', color='#82e88a', linewidth=2)\n",
    "    ax.legend(frameon=False)\n",
    "    ax.set_xlabel(\"Days\")\n",
    "    ax.set_ylabel(\"Share of Population\")\n",
    "    if 'fig_name' in args:\n",
    "        ax.figure.savefig('figures/' + args.fig_name + '.png')\n",
    "    else:\n",
    "        ax.figure.savefig('figures/sir_plot.png')\n",
    "    plt.close()\n",
    "    \n",
    "# Convenience function: access Python dict keys as dict.key instead of dict['key']\n",
    "class objdict(dict):\n",
    "    def __getattr__(self, name):\n",
    "        if name in self:\n",
    "            return self[name]\n",
    "        else:\n",
    "            raise AttributeError(\"No such attribute: \" + name)\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value\n",
    "\n",
    "    def __delattr__(self, name):\n",
    "        if name in self:\n",
    "            del self[name]\n",
    "        else:\n",
    "            raise AttributeError(\"No such attribute: \" + name)\n",
    "            \n",
    "# Run n simulations in parallel: for each run, parameters are randomly sampled from an interval\n",
    "# NOTE: Are these intervals reasonable?\n",
    "def multiprocess(args):\n",
    "\n",
    "    chunks = []\n",
    "    num_procs = args.randomize\n",
    "    for _ in range(num_procs):\n",
    "        d = dict()\n",
    "        d['origin_matrix_path'] = args.origin_matrix_path\n",
    "        d['thresh1'] = np.random.randint(0, 350)\n",
    "        d['thresh2'] = np.random.randint(d['thresh1'], 700)\n",
    "        d['infection_magnitude'] = np.random.randint(5, 15)\n",
    "        d['beta'] = 1.6\n",
    "        d['gamma'] = 0.04\n",
    "        d['public_trans'] = np.random.randint(1, 7) * 0.1\n",
    "        d['days'] = 200\n",
    "        d['fig_name'] = 'public_trans_{:0.1f}_({}, {})_inf_{}'.format(d['public_trans'], d['thresh1'], d['thresh2'], d['infection_magnitude'])\n",
    "        d['loading'] = args.loading\n",
    "        d = objdict(d)\n",
    "        chunks.append(d)\n",
    "\n",
    "    with Pool(num_procs) as p:\n",
    "        p.map(covid_sim, chunks)\n",
    "\n",
    "    p.join()\n",
    "\n",
    "def covid_sim(args):\n",
    "    # Read in origin-destination flow matrix\n",
    "    if int(args.loading) == 0:\n",
    "        OD = np.genfromtxt(args.origin_matrix_path, delimiter=',')\n",
    "        \n",
    "    elif int(args.loading) == 1:\n",
    "        OD = pd.read_csv('data/nyc_od.csv', header=None, dtype=np.float64).to_numpy()\n",
    "        \n",
    "    elif int(args.loading) == 2:\n",
    "        OD = feather.read_dataframe('data/nyc_od.feather').to_numpy()\n",
    "    \n",
    "\n",
    "    # initialize the population vector from the origin-destination flow matrix\n",
    "    N_k = np.abs(np.diagonal(OD) + OD.sum(axis=0) - OD.sum(axis=1))\n",
    "    locs_len = len(N_k)                 # number of locations\n",
    "    SIR = np.zeros(shape=(locs_len, 3)) # make a numpy array with 3 columns for keeping track of the S, I, R groups\n",
    "    SIR[:,0] = N_k                      # initialize the S group with the respective populations\n",
    "    thresh1 = args.thresh1\n",
    "    thresh2 = args.thresh2\n",
    "\n",
    "    first_infections = np.where((thresh1 <= SIR[:, 0]) & (SIR[:, 0] <= thresh2), np.random.randint(1, args.infection_magnitude), 0)   # for demo purposes, randomly introduce infections\n",
    "    # NOTE: this is arbitrary but not actually random.... \n",
    "    SIR[:, 0] = SIR[:, 0] - first_infections\n",
    "    SIR[:, 1] = SIR[:, 1] + first_infections                           # move infections to the I group\n",
    "\n",
    "    # row normalize the SIR matrix for keeping track of group proportions\n",
    "    row_sums = SIR.sum(axis=1)\n",
    "    SIR_n = SIR / row_sums[:, np.newaxis]\n",
    "\n",
    "    # initialize parameters\n",
    "    beta = args.beta\n",
    "    gamma = args.gamma\n",
    "    public_trans = args.public_trans                                 # alpha\n",
    "    R0 = beta/gamma\n",
    "    beta_vec = np.random.gamma(1.6, 2, locs_len)\n",
    "    gamma_vec = np.full(locs_len, gamma)\n",
    "    public_trans_vec = np.full(locs_len, public_trans)\n",
    "\n",
    "    # make copy of the SIR matrices \n",
    "    SIR_sim = SIR.copy()\n",
    "    SIR_nsim = SIR_n.copy()\n",
    "\n",
    "    # run model\n",
    "    #print(SIR_sim.sum(axis=0).sum() == N_k.sum())\n",
    "    infected_pop_norm = []\n",
    "    susceptible_pop_norm = []\n",
    "    recovered_pop_norm = []\n",
    "    days = 100\n",
    "    for time_step in tqdm(range(days)):\n",
    "        infected_mat = np.array([SIR_nsim[:,1],]*locs_len).transpose()\n",
    "        OD_infected = np.round(OD*infected_mat)\n",
    "        inflow_infected = OD_infected.sum(axis=0)\n",
    "        inflow_infected = np.round(inflow_infected*public_trans_vec)\n",
    "        #print('total infected inflow: ', inflow_infected.sum())\n",
    "        new_infect = beta_vec*SIR_sim[:, 0]*inflow_infected/(N_k + OD.sum(axis=0))\n",
    "        new_recovered = gamma_vec*SIR_sim[:, 1]\n",
    "        new_infect = np.where(new_infect>SIR_sim[:, 0], SIR_sim[:, 0], new_infect)\n",
    "        SIR_sim[:, 0] = SIR_sim[:, 0] - new_infect\n",
    "        SIR_sim[:, 1] = SIR_sim[:, 1] + new_infect - new_recovered\n",
    "        SIR_sim[:, 2] = SIR_sim[:, 2] + new_recovered\n",
    "        SIR_sim = np.where(SIR_sim<0,0,SIR_sim)\n",
    "        # recompute the normalized SIR matrix\n",
    "        row_sums = SIR_sim.sum(axis=1)\n",
    "        SIR_nsim = SIR_sim / row_sums[:, np.newaxis]\n",
    "        S = SIR_sim[:,0].sum()/N_k.sum()\n",
    "        I = SIR_sim[:,1].sum()/N_k.sum()\n",
    "        R = SIR_sim[:,2].sum()/N_k.sum()\n",
    "        #print(S, I, R, (S+I+R)*N_k.sum(), N_k.sum())\n",
    "        #print('\\n')\n",
    "        infected_pop_norm.append(I)\n",
    "        susceptible_pop_norm.append(S)\n",
    "        recovered_pop_norm.append(R)\n",
    "\n",
    "    graphing_function(args, days, (susceptible_pop_norm, infected_pop_norm, recovered_pop_norm))\n",
    "\n",
    "def covid_sim_serial(args):\n",
    "    for i in range(args.randomize):\n",
    "        covid_sim(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 28.81it/s]\n",
      "100%|██████████| 100/100 [00:03<00:00, 32.97it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.95it/s]\n",
      "100%|██████████| 100/100 [00:04<00:00, 24.81it/s]\n"
     ]
    }
   ],
   "source": [
    "%lprun -f covid_sim_serial covid_sim_serial(args3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 14.2226 s\n",
    "File: /Users/sree/.ipython/cython/_cython_magic_192a6ecac340796dc67f00b840b5d0f2.pyx\n",
    "Function: covid_sim_serial at line 157\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "   157                                           def covid_sim_serial(args):\n",
    "   158         5         13.0      2.6      0.0      for i in range(args.randomize):\n",
    "   159         4   14222618.0 3555654.5    100.0          covid_sim(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 11.80it/s]\n",
      "\n",
      "100%|██████████| 100/100 [00:09<00:00, 11.56it/s]\n",
      "100%|██████████| 100/100 [00:09<00:00, 11.25it/s]\n"
     ]
    }
   ],
   "source": [
    "%lprun -f multiprocess multiprocess(args3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 10.3618 s\n",
    "File: /Users/sree/.ipython/cython/_cython_magic_192a6ecac340796dc67f00b840b5d0f2.pyx\n",
    "Function: multiprocess at line 58\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    58                                           def multiprocess(args):\n",
    "    59                                           \n",
    "    60         1          4.0      4.0      0.0      chunks = []\n",
    "    61         1          1.0      1.0      0.0      num_procs = args.randomize\n",
    "    62         5          5.0      1.0      0.0      for _ in range(num_procs):\n",
    "    63         4          1.0      0.2      0.0          d = dict()\n",
    "    64         4          3.0      0.8      0.0          d['origin_matrix_path'] = args.origin_matrix_path\n",
    "    65         4         24.0      6.0      0.0          d['thresh1'] = np.random.randint(0, 350)\n",
    "    66         4          9.0      2.2      0.0          d['thresh2'] = np.random.randint(d['thresh1'], 700)\n",
    "    67         4          6.0      1.5      0.0          d['infection_magnitude'] = np.random.randint(5, 15)\n",
    "    68         4          3.0      0.8      0.0          d['beta'] = 1.6\n",
    "    69         4          2.0      0.5      0.0          d['gamma'] = 0.04\n",
    "    70         4          7.0      1.8      0.0          d['public_trans'] = np.random.randint(1, 7) * 0.1\n",
    "    71         4          1.0      0.2      0.0          d['days'] = 200\n",
    "    72         4         10.0      2.5      0.0          d['fig_name'] = 'public_trans_{:0.1f}_({}, {})_inf_{}'.format(d['public_trans'], d['thresh1'], d['thresh2'], d['infection_magnitude'])\n",
    "    73         4          2.0      0.5      0.0          d['loading'] = args.loading\n",
    "    74         4          5.0      1.2      0.0          d = objdict(d)\n",
    "    75         4          1.0      0.2      0.0          chunks.append(d)\n",
    "    76                                           \n",
    "    77         1      33542.0  33542.0      0.3      with Pool(num_procs) as p:\n",
    "    78         1   10326529.0 10326529.0     99.7          p.map(covid_sim, chunks)\n",
    "    79                                           \n",
    "    80         1       1681.0   1681.0      0.0      p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a slight speed up when compiling with Cython without specifying the types of the variables for both serial and multiprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 34.33it/s]\n"
     ]
    }
   ],
   "source": [
    "%lprun -f covid_sim covid_sim(args3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cython + Removing tqdm\n",
    "\n",
    "We wanted to see if removing tqdm could provide an additional speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "# cython: profile=True\n",
    "# cython: linetrace=True\n",
    "# cython: binding=True\n",
    "# distutils: define_macros=CYTHON_TRACE_NOGIL=1\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "from multiprocessing import cpu_count\n",
    "from functools import partial\n",
    "from multiprocessing.pool import Pool\n",
    "import pandas as pd\n",
    "import feather\n",
    "\n",
    "# Matplotlib doesn't play nicely with multiprocessing, so\n",
    "# we have to create a separate graphing function & import matplotlib inside of that.\n",
    "def graphing_function(args, days, norms):\n",
    "    import matplotlib.pyplot as plt\n",
    "    susceptible_pop_norm, infected_pop_norm, recovered_pop_norm = norms\n",
    "    # plot results and save the plot\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.plot(np.arange(days), susceptible_pop_norm, label='Susceptible', color='#4aa5f0', linewidth=2)\n",
    "    ax.plot(np.arange(days), infected_pop_norm, label='Infected', color='#f03737', linewidth=2)\n",
    "    ax.plot(np.arange(days), recovered_pop_norm, label='Recovered', color='#82e88a', linewidth=2)\n",
    "    ax.legend(frameon=False)\n",
    "    ax.set_xlabel(\"Days\")\n",
    "    ax.set_ylabel(\"Share of Population\")\n",
    "    if 'fig_name' in args:\n",
    "        ax.figure.savefig('figures/' + args.fig_name + '.png')\n",
    "    else:\n",
    "        ax.figure.savefig('figures/sir_plot.png')\n",
    "    plt.close()\n",
    "    \n",
    "# Convenience function: access Python dict keys as dict.key instead of dict['key']\n",
    "class objdict(dict):\n",
    "    def __getattr__(self, name):\n",
    "        if name in self:\n",
    "            return self[name]\n",
    "        else:\n",
    "            raise AttributeError(\"No such attribute: \" + name)\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value\n",
    "\n",
    "    def __delattr__(self, name):\n",
    "        if name in self:\n",
    "            del self[name]\n",
    "        else:\n",
    "            raise AttributeError(\"No such attribute: \" + name)\n",
    "            \n",
    "# Run n simulations in parallel: for each run, parameters are randomly sampled from an interval\n",
    "# NOTE: Are these intervals reasonable?\n",
    "def multiprocess(args):\n",
    "\n",
    "    chunks = []\n",
    "    num_procs = args.randomize\n",
    "    for _ in range(num_procs):\n",
    "        d = dict()\n",
    "        d['origin_matrix_path'] = args.origin_matrix_path\n",
    "        d['thresh1'] = np.random.randint(0, 350)\n",
    "        d['thresh2'] = np.random.randint(d['thresh1'], 700)\n",
    "        d['infection_magnitude'] = np.random.randint(5, 15)\n",
    "        d['beta'] = 1.6\n",
    "        d['gamma'] = 0.04\n",
    "        d['public_trans'] = np.random.randint(1, 7) * 0.1\n",
    "        d['days'] = 200\n",
    "        d['fig_name'] = 'public_trans_{:0.1f}_({}, {})_inf_{}'.format(d['public_trans'], d['thresh1'], d['thresh2'], d['infection_magnitude'])\n",
    "        d['loading'] = args.loading\n",
    "        d = objdict(d)\n",
    "        chunks.append(d)\n",
    "\n",
    "    with Pool(num_procs) as p:\n",
    "        p.map(covid_sim, chunks)\n",
    "\n",
    "    p.join()\n",
    "\n",
    "def covid_sim(args):\n",
    "    # Read in origin-destination flow matrix\n",
    "    if int(args.loading) == 0:\n",
    "        OD = np.genfromtxt(args.origin_matrix_path, delimiter=',')\n",
    "        \n",
    "    elif int(args.loading) == 1:\n",
    "        OD = pd.read_csv('data/nyc_od.csv', header=None, dtype=np.float64).to_numpy()\n",
    "        \n",
    "    elif int(args.loading) == 2:\n",
    "        OD = feather.read_dataframe('data/nyc_od.feather').to_numpy()\n",
    "    \n",
    "\n",
    "    # initialize the population vector from the origin-destination flow matrix\n",
    "    N_k = np.abs(np.diagonal(OD) + OD.sum(axis=0) - OD.sum(axis=1))\n",
    "    locs_len = len(N_k)                 # number of locations\n",
    "    SIR = np.zeros(shape=(locs_len, 3)) # make a numpy array with 3 columns for keeping track of the S, I, R groups\n",
    "    SIR[:,0] = N_k                      # initialize the S group with the respective populations\n",
    "    thresh1 = args.thresh1\n",
    "    thresh2 = args.thresh2\n",
    "\n",
    "    first_infections = np.where((thresh1 <= SIR[:, 0]) & (SIR[:, 0] <= thresh2), np.random.randint(1, args.infection_magnitude), 0)   # for demo purposes, randomly introduce infections\n",
    "    # NOTE: this is arbitrary but not actually random.... \n",
    "    SIR[:, 0] = SIR[:, 0] - first_infections\n",
    "    SIR[:, 1] = SIR[:, 1] + first_infections                           # move infections to the I group\n",
    "\n",
    "    # row normalize the SIR matrix for keeping track of group proportions\n",
    "    row_sums = SIR.sum(axis=1)\n",
    "    SIR_n = SIR / row_sums[:, np.newaxis]\n",
    "\n",
    "    # initialize parameters\n",
    "    beta = args.beta\n",
    "    gamma = args.gamma\n",
    "    public_trans = args.public_trans                                 # alpha\n",
    "    R0 = beta/gamma\n",
    "    beta_vec = np.random.gamma(1.6, 2, locs_len)\n",
    "    gamma_vec = np.full(locs_len, gamma)\n",
    "    public_trans_vec = np.full(locs_len, public_trans)\n",
    "\n",
    "    # make copy of the SIR matrices \n",
    "    SIR_sim = SIR.copy()\n",
    "    SIR_nsim = SIR_n.copy()\n",
    "\n",
    "    # run model\n",
    "    #print(SIR_sim.sum(axis=0).sum() == N_k.sum())\n",
    "    infected_pop_norm = []\n",
    "    susceptible_pop_norm = []\n",
    "    recovered_pop_norm = []\n",
    "    days = 100\n",
    "    for time_step in range(days):\n",
    "        infected_mat = np.array([SIR_nsim[:,1],]*locs_len).transpose()\n",
    "        OD_infected = np.round(OD*infected_mat)\n",
    "        inflow_infected = OD_infected.sum(axis=0)\n",
    "        inflow_infected = np.round(inflow_infected*public_trans_vec)\n",
    "        #print('total infected inflow: ', inflow_infected.sum())\n",
    "        new_infect = beta_vec*SIR_sim[:, 0]*inflow_infected/(N_k + OD.sum(axis=0))\n",
    "        new_recovered = gamma_vec*SIR_sim[:, 1]\n",
    "        new_infect = np.where(new_infect>SIR_sim[:, 0], SIR_sim[:, 0], new_infect)\n",
    "        SIR_sim[:, 0] = SIR_sim[:, 0] - new_infect\n",
    "        SIR_sim[:, 1] = SIR_sim[:, 1] + new_infect - new_recovered\n",
    "        SIR_sim[:, 2] = SIR_sim[:, 2] + new_recovered\n",
    "        SIR_sim = np.where(SIR_sim<0,0,SIR_sim)\n",
    "        # recompute the normalized SIR matrix\n",
    "        row_sums = SIR_sim.sum(axis=1)\n",
    "        SIR_nsim = SIR_sim / row_sums[:, np.newaxis]\n",
    "        S = SIR_sim[:,0].sum()/N_k.sum()\n",
    "        I = SIR_sim[:,1].sum()/N_k.sum()\n",
    "        R = SIR_sim[:,2].sum()/N_k.sum()\n",
    "        #print(S, I, R, (S+I+R)*N_k.sum(), N_k.sum())\n",
    "        #print('\\n')\n",
    "        infected_pop_norm.append(I)\n",
    "        susceptible_pop_norm.append(S)\n",
    "        recovered_pop_norm.append(R)\n",
    "\n",
    "    graphing_function(args, days, (susceptible_pop_norm, infected_pop_norm, recovered_pop_norm))\n",
    "\n",
    "def covid_sim_serial(args):\n",
    "    for i in range(args.randomize):\n",
    "        covid_sim(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f covid_sim_serial covid_sim_serial(args3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 11.9808 s\n",
    "File: /Users/sree/.ipython/cython/_cython_magic_adb40bf18cf3302aa647adf2af62d3bc.pyx\n",
    "Function: covid_sim_serial at line 156\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "   156                                           def covid_sim_serial(args):\n",
    "   157         5         22.0      4.4      0.0      for i in range(args.randomize):\n",
    "   158         4   11980753.0 2995188.2    100.0          covid_sim(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f multiprocess multiprocess(args3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 8.57453 s\n",
    "File: /Users/sree/.ipython/cython/_cython_magic_adb40bf18cf3302aa647adf2af62d3bc.pyx\n",
    "Function: multiprocess at line 57\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    57                                           def multiprocess(args):\n",
    "    58                                           \n",
    "    59         1          1.0      1.0      0.0      chunks = []\n",
    "    60         1          1.0      1.0      0.0      num_procs = args.randomize\n",
    "    61         5          5.0      1.0      0.0      for _ in range(num_procs):\n",
    "    62         4          1.0      0.2      0.0          d = dict()\n",
    "    63         4          4.0      1.0      0.0          d['origin_matrix_path'] = args.origin_matrix_path\n",
    "    64         4         26.0      6.5      0.0          d['thresh1'] = np.random.randint(0, 350)\n",
    "    65         4         10.0      2.5      0.0          d['thresh2'] = np.random.randint(d['thresh1'], 700)\n",
    "    66         4          8.0      2.0      0.0          d['infection_magnitude'] = np.random.randint(5, 15)\n",
    "    67         4          2.0      0.5      0.0          d['beta'] = 1.6\n",
    "    68         4          1.0      0.2      0.0          d['gamma'] = 0.04\n",
    "    69         4          6.0      1.5      0.0          d['public_trans'] = np.random.randint(1, 7) * 0.1\n",
    "    70         4          0.0      0.0      0.0          d['days'] = 200\n",
    "    71         4          8.0      2.0      0.0          d['fig_name'] = 'public_trans_{:0.1f}_({}, {})_inf_{}'.format(d['public_trans'], d['thresh1'], d['thresh2'], d['infection_magnitude'])\n",
    "    72         4          0.0      0.0      0.0          d['loading'] = args.loading\n",
    "    73         4          4.0      1.0      0.0          d = objdict(d)\n",
    "    74         4          0.0      0.0      0.0          chunks.append(d)\n",
    "    75                                           \n",
    "    76         1      36616.0  36616.0      0.4      with Pool(num_procs) as p:\n",
    "    77         1    8536431.0 8536431.0     99.6          p.map(covid_sim, chunks)\n",
    "    78                                           \n",
    "    79         1       1406.0   1406.0      0.0      p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using feature for loading, using Cython and removing tqdm provided a time reduction for both serial and parallel processes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
